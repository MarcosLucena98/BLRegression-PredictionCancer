{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11047619,"sourceType":"datasetVersion","datasetId":6882057}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T01:54:03.082746Z","iopub.execute_input":"2025-03-17T01:54:03.082987Z","iopub.status.idle":"2025-03-17T01:54:04.256001Z","shell.execute_reply.started":"2025-03-17T01:54:03.082964Z","shell.execute_reply":"2025-03-17T01:54:04.254752Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Binary Logistic Regression For Cancer Prediction\n\nIn this study, we developed a predictive model using **Binary Logistic Regression** implemented with `sm.Logit` from the **statsmodels** package in Python. The model was trained to classify cancer cases based on genomic data.\n\nAfter building the model, we evaluated its performance using key metrics, including the **ROC Curve, GINI coefficient, Precision, Specificity, and Sensitivity**. These metrics help assess the model’s accuracy and reliability in detecting cancer cases.","metadata":{}},{"cell_type":"code","source":"# In[0.1]: Package installation\n\n!pip install pandas\n!pip install numpy\n!pip install -U seaborn\n!pip install matplotlib\n!pip install plotly\n!pip install scipy\n!pip install statsmodels\n!pip install scikit-learn\n!pip install statstests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:00:49.732826Z","iopub.execute_input":"2025-03-17T02:00:49.733281Z","iopub.status.idle":"2025-03-17T02:01:28.986553Z","shell.execute_reply.started":"2025-03-17T02:00:49.733248Z","shell.execute_reply":"2025-03-17T02:01:28.985278Z"},"collapsed":true,"jupyter":{"source_hidden":true,"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In[0.2]: Package Import\n\nimport pandas as pd # data manipulation in dataframe format\nimport numpy as np # mathematical operations\nimport seaborn as sns # graphical visualization\nimport matplotlib.pyplot as plt # graphical visualization\nfrom scipy.interpolate import UnivariateSpline # smoothed sigmoid curve\nimport statsmodels.api as sm # model estimation\nimport statsmodels.formula.api as smf # binary logistic model estimation\nfrom statstests.process import stepwise # Stepwise procedure\nfrom scipy import stats # chi2 statistics\nimport plotly.graph_objects as go # 3D graphics\nfrom statsmodels.iolib.summary2 import summary_col # model comparison\nfrom statsmodels.discrete.discrete_model import MNLogit # multinomial logistic model estimation\nimport warnings\nfrom sklearn.preprocessing import MinMaxScaler\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:02:34.846375Z","iopub.execute_input":"2025-03-17T02:02:34.846716Z","iopub.status.idle":"2025-03-17T02:02:37.244862Z","shell.execute_reply.started":"2025-03-17T02:02:34.846689Z","shell.execute_reply":"2025-03-17T02:02:37.244033Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In[0.3] Loading the Data\n\n# Assigning the data to the variable df_cancer\ndf_cancer = pd.read_csv('/kaggle/input/genomic-data-for-cancer/gene_expression.csv')\n\n# Removing spaces from variable labels\ndf_cancer.columns = df_cancer.columns.str.replace(' ', '_')\n\ndf_cancer.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:03:22.759041Z","iopub.execute_input":"2025-03-17T02:03:22.759424Z","iopub.status.idle":"2025-03-17T02:03:22.772834Z","shell.execute_reply.started":"2025-03-17T02:03:22.759395Z","shell.execute_reply":"2025-03-17T02:03:22.771711Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model Evaluation and Results  \n\nThe **Binary Logistic Regression** model for cancer prediction shows strong predictive capability, as evidenced by a **Pseudo R-squared value of 0.5441**, indicating that the independent variables explain a substantial proportion of the variability in cancer presence.  \n\nThe **log-likelihood improved** significantly from -2079.4 (null model) to -948.05, reinforcing the model's effectiveness. Additionally, the **LLR p-value < 0.000** confirms that the model as a whole is statistically significant.  \n\n#### Coefficients Analysis:  \n- **Intercept (3.7855, p < 0.001):** A strong positive base probability for cancer presence.  \n- **Gene_One (0.6145, p < 0.001):** Positively correlated with cancer presence, meaning higher expression increases the probability of cancer.  \n- **Gene_Two (-1.3362, p < 0.001):** Negatively correlated, indicating higher expression decreases cancer likelihood.  \n\nAll coefficients are **statistically significant (p < 0.001)**, highlighting their strong influence on cancer prediction.","metadata":{}},{"cell_type":"code","source":"# In[0.4] Formula Model and Model\n\nFormula_model = \"Cancer_Present ~ Gene_One + Gene_Two\"\n\nmodel_cancer = sm.Logit.from_formula(Formula_model, df_cancer).fit()\n\nmodel_cancer.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:08:48.649239Z","iopub.execute_input":"2025-03-17T02:08:48.649582Z","iopub.status.idle":"2025-03-17T02:08:48.725163Z","shell.execute_reply.started":"2025-03-17T02:08:48.649550Z","shell.execute_reply":"2025-03-17T02:08:48.724193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Confusion Matrix Function\n\nThis function generates a confusion matrix to evaluate the performance of a classification model. It calculates sensitivity, specificity, and accuracy based on a given cutoff value. The confusion matrix is displayed as a plot for better visualization.\n","metadata":{}},{"cell_type":"code","source":"# In[0.5] Building the Function for the Confusion Matrix\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score,\\\n    ConfusionMatrixDisplay, recall_score\n\ndef confusion_matrix_function(predicts, observed, cutoff):\n    \n    values = predicts.values\n    \n    binary_prediction = []\n        \n    for item in values:\n        if item < cutoff:\n            binary_prediction.append(0)\n        else:\n            binary_prediction.append(1)\n           \n    cm = confusion_matrix(binary_prediction, observed)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot()\n    plt.xlabel('True')\n    plt.ylabel('Classified')\n    plt.gca().invert_xaxis()\n    plt.gca().invert_yaxis()\n    plt.show()\n        \n    sensitivity = recall_score(observed, binary_prediction, pos_label=1)\n    specificity = recall_score(observed, binary_prediction, pos_label=0)\n    accuracy = accuracy_score(observed, binary_prediction)\n\n    # Visualizing the main indicators of this confusion matrix\n    indicators = pd.DataFrame({'Sensitivity':[sensitivity],\n                               'Specificity':[specificity],\n                               'Accuracy':[accuracy]})\n    return indicators","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:17:07.262283Z","iopub.execute_input":"2025-03-17T02:17:07.262665Z","iopub.status.idle":"2025-03-17T02:17:07.464985Z","shell.execute_reply.started":"2025-03-17T02:17:07.262634Z","shell.execute_reply":"2025-03-17T02:17:07.464008Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Confusion Matrix Analysis and Model Performance\n\nThe confusion matrix and performance metrics indicate that the model performs well in predicting cancer presence:  \n\n- **Sensitivity (85.73%)**: The model correctly identifies 85.73% of actual cancer cases, meaning it effectively detects positive cases.  \n- **Specificity (85.67%)**: The model correctly identifies 85.67% of non-cancer cases, reducing false positives.  \n- **Accuracy (85.7%)**: Overall, the model classifies cases correctly in 85.7% of instances.  \n\nWith **1286 true positives (TP)** and **1285 true negatives (TN)**, the model demonstrates a balanced performance. However, the **214 false positives (FP)** and **215 false negatives (FN)** indicate areas for improvement, particularly in reducing misclassifications.","metadata":{}},{"cell_type":"code","source":"# In[0.6] Construção da matriz de confusão\n\n# Adicionando os valores previstos de probabilidade na base de dados criando a coluna PHat\ndf_cancer['phat'] = model_cancer.predict()\n\n# Matriz de confusão para cutoff = 0.5\nconfusion_matrix_function(observed=df_cancer['Cancer_Present'],\n                predicts=df_cancer['phat'],\n                cutoff=0.50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:17:09.901270Z","iopub.execute_input":"2025-03-17T02:17:09.901590Z","iopub.status.idle":"2025-03-17T02:17:10.184907Z","shell.execute_reply.started":"2025-03-17T02:17:09.901566Z","shell.execute_reply":"2025-03-17T02:17:10.183864Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Analyzing Sensitivity and Specificity Across Different Cutoff Points**\n\nThis code is designed to analyze the behavior of **sensitivity and specificity** across different cutoff values, ranging from **0 to 1**.  \n\nThe function **`spec_sens`** takes observed values and predicted probabilities as input and evaluates how **sensitivity and specificity change** for each cutoff point in increments of **0.01**.  \n\nBy iterating through the cutoff range, it classifies predictions as **binary (0 or 1)** and computes **sensitivity (recall for positive class) and specificity (recall for negative class)**, storing the results in a DataFrame for further analysis.","metadata":{}},{"cell_type":"code","source":"# In[0.7] Equalizing specificity and sensitivity criteria for educational purposes\n\ndef spec_sens(observed, predicts):\n    \n    # Add object with the predicted values\n    values = predicts.values\n    \n    # Range of cutoffs to be analyzed in steps of 0.01\n    cutoffs = np.arange(0, 1.01, 0.01)\n    \n    # Lists to store specificity and sensitivity results\n    sensitivity_list = []\n    specificity_list = []\n    \n    for cutoff in cutoffs:\n        \n        binary_prediction = []\n        \n        # Defining binary result according to the prediction\n        for item in values:\n            if item >= cutoff:\n                binary_prediction.append(1)\n            else:\n                binary_prediction.append(0)\n                \n        # Calculate sensitivity and specificity for the cutoff\n        sensitivity = recall_score(observed, binary_prediction, pos_label=1)\n        specificity = recall_score(observed, binary_prediction, pos_label=0)\n        \n        # Add values to the lists\n        sensitivity_list.append(sensitivity)\n        specificity_list.append(specificity)\n        \n    # Create dataframe with results for their respective cutoffs\n    result = pd.DataFrame({'cutoffs': cutoffs, 'sensitivity': sensitivity_list, 'specificity': specificity_list})\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:17:18.646768Z","iopub.execute_input":"2025-03-17T02:17:18.647103Z","iopub.status.idle":"2025-03-17T02:17:18.653541Z","shell.execute_reply.started":"2025-03-17T02:17:18.647076Z","shell.execute_reply":"2025-03-17T02:17:18.652363Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In[0.8] We create a dataframe that contains the vectors 'sensitivity', 'specificity', and 'cutoffs'\n\nplotting_data = spec_sens(observed = df_cancer['Cancer_Present'],\n                          predicts = df_cancer['phat'])\nplotting_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:17:41.064967Z","iopub.execute_input":"2025-03-17T02:17:41.065364Z","iopub.status.idle":"2025-03-17T02:17:41.975481Z","shell.execute_reply.started":"2025-03-17T02:17:41.065334Z","shell.execute_reply":"2025-03-17T02:17:41.974402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In this graph, you can see the result of sensitivity and specificity across different cutoff points. I created a graph that shows sensitivity and specificity at various cutoff points, and approximately, the cutoff of 0.5 is where the intersection of sensitivity and specificity occurs.","metadata":{}},{"cell_type":"code","source":"# In[0.9]: Plotting a graph that shows the variation of specificity and sensitivity as a function of the cutoff\n\nplt.figure(figsize=(15,10))\nwith plt.style.context('seaborn-v0_8-whitegrid'):\n    plt.plot(plotting_data.cutoffs, plotting_data.sensitivity, marker='o',\n         color='indigo', markersize=8)\n    plt.plot(plotting_data.cutoffs, plotting_data.specificity, marker='o',\n         color='limegreen', markersize=8)\nplt.xlabel('Cutoff', fontsize=20)\nplt.ylabel('Sensitivity / Specificity', fontsize=20)\nplt.xticks(np.arange(0, 1.1, 0.2), fontsize=14)\nplt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\nplt.legend(['Sensitivity', 'Specificity'], fontsize=20)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:17:56.798741Z","iopub.execute_input":"2025-03-17T02:17:56.799076Z","iopub.status.idle":"2025-03-17T02:17:57.052534Z","shell.execute_reply.started":"2025-03-17T02:17:56.799050Z","shell.execute_reply":"2025-03-17T02:17:57.051424Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The ROC curve with an AUC of 0.9392 and the Gini coefficient of 0.8785 both show that the model performs very well. \n\n- **AUC = 0.9392** indicates that the model is great at distinguishing between classes (e.g., fraud vs. non-fraud).\n- **Gini = 0.8785** confirms this, showing the model has strong predictive power.\n\nOverall, these results suggest that the model is highly effective and performs well in identifying fraud with minimal errors.","metadata":{}},{"cell_type":"code","source":"# In[1.0] Construction of the ROC Curve\n\nfrom sklearn.metrics import roc_curve, auc\n\n# 'roc_curve' function from the 'metrics' package in sklearn\n\nfpr, tpr, thresholds = roc_curve(df_cancer['Cancer_Present'],\n                                 df_cancer['phat'])\nroc_auc = auc(fpr, tpr)\n\n# Calculation of the GINI coefficient\ngini = (roc_auc - 0.5) / (0.5)\n\n# Plotting the ROC curve\nplt.figure(figsize=(15,10))\nplt.plot(fpr, tpr, marker='o', color='darkorchid', markersize=10, linewidth=3)\nplt.plot(fpr, fpr, color='gray', linestyle='dashed')\nplt.title('Area under the curve: %g' % round(roc_auc, 4) +\n          ' | GINI Coefficient: %g' % round(gini, 4), fontsize=22)\nplt.xlabel('1 - Specificity', fontsize=20)\nplt.ylabel('Sensitivity', fontsize=20)\nplt.xticks(np.arange(0, 1.1, 0.2), fontsize=14)\nplt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:18:09.678502Z","iopub.execute_input":"2025-03-17T02:18:09.678834Z","iopub.status.idle":"2025-03-17T02:18:09.913137Z","shell.execute_reply.started":"2025-03-17T02:18:09.678808Z","shell.execute_reply":"2025-03-17T02:18:09.912084Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Conclusion**\n\nIn conclusion, using the binary logistic regression model from the `statsmodels` package in Python, the results obtained—AUC of 0.9392 and Gini coefficient of 0.8785—demonstrate that the model is highly effective in distinguishing between the two classes (e.g., fraud vs. non-fraud). These strong performance metrics indicate that the model is well-suited for the task, providing accurate predictions with minimal errors. Overall, the logistic regression model shows great promise in detecting fraud or other binary outcomes, making it a reliable tool for such applications.","metadata":{}}]}